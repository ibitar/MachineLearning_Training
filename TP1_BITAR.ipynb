{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctJOkCb59Ami"
   },
   "source": [
    "# TP1 Machine Learning - Année 4 - ESILV - Septembre 2023\n",
    "Ibrahim BITAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_-eu0DKmEt1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ColumnTransformer class to handle data variety into one object\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# a pipeline to chain operations\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# preprocessing operations\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# ML-models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numpy et pandas sont deux bibliothèques Python populaires pour la manipulation de données. numpy est principalement utilisé pour effectuer des opérations numériques sur des tableaux, tandis que pandas est utilisé pour travailler avec des données tabulaires (comme les données CSV) en utilisant des structures de données appelées DataFrames.\n",
    "\n",
    "\n",
    "- ColumnTransformer est une classe fournie par la bibliothèque scikit-learn (sklearn). Elle permet de gérer différentes transformations sur les colonnes d'un jeu de données, ce qui est utile lorsque vous avez des colonnes avec différents types de données (numériques, catégoriques, textuelles) et que vous souhaitez les prétraiter de manière spécifique.\n",
    "\n",
    "- Pipeline est une classe de scikit-learn qui permet de créer un flux de travail de traitement des données et d'apprentissage automatique en chaînant plusieurs étapes. Vous pouvez spécifier une séquence d'opérations à effectuer, du prétraitement des données à l'apprentissage du modèle, le tout dans une seule structure.\n",
    "\n",
    "- SimpleImputer est utilisé pour gérer les valeurs manquantes dans les données en leur attribuant une valeur spécifique (par exemple, la moyenne des valeurs non manquantes).\n",
    "\n",
    "- StandardScaler est utilisé pour mettre à l'échelle les caractéristiques numériques afin qu'elles aient une moyenne de zéro et un écart-type de un. Cela est souvent nécessaire pour de nombreux algorithmes d'apprentissage automatique.\n",
    "\n",
    "- OneHotEncoder est utilisé pour transformer des variables catégorielles en variables binaires (0 ou 1) pour qu'elles puissent être utilisées dans les modèles d'apprentissage automatique.\n",
    "\n",
    "- LogisticRegression est un modèle d'apprentissage automatique couramment utilisé pour la classification binaire.\n",
    "train_test_split est une fonction de scikit-learn qui est utilisée pour diviser un ensemble de données en ensembles d'entraînement et de test, ce qui est essentiel pour évaluer la performance d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guIMQnm4puGX"
   },
   "source": [
    "As you can remark, a sample-data repository is created after running the previous code. You have access to california_housing_test.csv, california_housing_train.csv, mnist_test.csv and mnist_train_small.csv. You can import a local csv files to your sample_data repo. Let import now the winequality-red.csv that you can download to your local computer from this link  here: https://archive.ics.uci.edu/dataset/186/wine+quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyE2pVd-qdGr",
    "outputId": "e4778460-f60f-4e3a-c581-837c46c46e3d"
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"data/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_csv est une fonction de la bibliothèque pandas (pd) qui est utilisée pour lire un fichier CSV et le stocker dans un DataFrame, une structure de données tabulaire en deux dimensions.\n",
    "\n",
    "- \"data/winequality-red.csv\" est un chemin relatif vers le fichier CSV. Assurez-vous que le fichier se trouve dans un dossier `data` à la racine du projet.\n",
    "\n",
    "- Pour récupérer ce fichier si besoin, vous pouvez le télécharger depuis le [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv). Par exemple : `wget -O data/winequality-red.csv https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv`.\n",
    "\n",
    "- sep=';' spécifie le séparateur de colonnes dans le fichier CSV. Dans ce cas, le point-virgule (;) est utilisé comme séparateur. Par défaut, la virgule (,) est utilisée comme séparateur, mais cela peut varier selon les fichiers CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wine.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wine.head(3) est utilisé pour afficher les trois premières lignes du DataFrame wine. La méthode head() est couramment utilisée pour afficher un aperçu des premières lignes d'un DataFrame et est utile pour vérifier rapidement les données et s'assurer qu'elles ont été chargées correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJRnDzmy5N6D",
    "outputId": "503df65c-c502-4723-8ed2-b39d43c7b12e"
   },
   "outputs": [],
   "source": [
    "print(wine.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkyFyy7G54gJ",
    "outputId": "cadec7af-b81e-4d97-9737-6d8f9be1d173"
   },
   "outputs": [],
   "source": [
    "print(wine.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf9Q9svo9Jsg"
   },
   "source": [
    "print the histogramm of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "0lB8ZYeO8WFj",
    "outputId": "b4bfe2d0-e7a1-41a0-bf32-b31e86fde65c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wine.hist(bins=20,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wine.hist() est une méthode pandas qui génère un ensemble d'histogrammes pour toutes les colonnes numériques du DataFrame wine.\n",
    "- bins=50 spécifie le nombre de compartiments (ou barres) dans chaque histogramme. Dans ce cas, il y aura 50 barres pour chaque histogramme.\n",
    "- figsize=(20, 15) définit la taille de la figure qui sera générée. Ici, la figure aura une largeur de 20 unités et une hauteur de 15 unités."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wORGjB0lCz4j"
   },
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "471yqNqCC9vr",
    "outputId": "f5e90a8b-8637-4193-91a6-0e37249d8cd3"
   },
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "z2G6YycqC9zp",
    "outputId": "e6c96cdc-d49b-44af-d058-38d53cb56e27"
   },
   "outputs": [],
   "source": [
    "wine.plot(kind='box', subplots=True, layout=(3,4), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "dt-SSqF5I5EA",
    "outputId": "659ab3d4-7b8a-48ce-8d2d-6058598d2334"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "correlations = wine.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = numpy.arange(0,12,1)\n",
    "names= wine.head(0)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names,rotation=90)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code génère une matrice de corrélation et la visualise sous forme d'une carte de chaleur (heatmap) en utilisant la bibliothèque Matplotlib. Voici des commentaires détaillés expliquant chaque ligne :\n",
    "\n",
    "- wine.corr() calcule la matrice de corrélation pour toutes les paires de colonnes numériques dans le DataFrame wine. Cette matrice contient les coefficients de corrélation de Pearson, qui mesurent la relation linéaire entre les variables.\n",
    "\n",
    "- ax.matshow() est utilisé pour afficher la matrice de corrélation correlations sous forme d'une carte de chaleur (heatmap) sur l'axe ax. Les valeurs plus faibles seront affichées en bleu, les valeurs plus fortes en rouge, et la gamme de couleurs est définie par vmin et vmax pour aller de -1 à 1\n",
    "\n",
    "- numpy.arange(0, 12, 1) crée une séquence d'entiers allant de 0 à 11 (12 non inclus), qui sera utilisée comme marques de graduation sur les axes x et y de la carte de chaleur.\n",
    "\n",
    "Cette carte de chaleur permet de visualiser les relations entre les différentes variables numériques dans le jeu de données sur la qualité du vin. Les cases plus foncées indiquent une corrélation plus forte, tandis que les cases plus claires indiquent une corrélation plus faible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "QzzzSrq9MFeO",
    "outputId": "09c442da-b7bc-4b17-a73e-e2989cae2a6f"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(wine,figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaque case de la matrice contient un diagramme de dispersion qui montre la relation entre deux variables numériques. La diagonale de la matrice contient des histogrammes de chaque variable par elle-même.\n",
    "\n",
    "- Cette matrice permet de visualiser les relations entre toutes les paires de variables numériques dans le jeu de données sur la qualité du vin. Elle est utile pour détecter des tendances, des regroupements ou des valeurs aberrantes dans les données. Chaque diagramme de dispersion montre comment deux variables numériques sont distribuées et s'il existe une relation linéaire entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB-oBkfPfnXy"
   },
   "source": [
    "SKlearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-byNzLh3fuIB"
   },
   "outputs": [],
   "source": [
    "#import classes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarques \n",
    "### StandardScaler \n",
    "C'est une classe de scikit-learn qui est utilisée pour mettre à l'échelle les caractéristiques numériques d'un ensemble de données. La mise à l'échelle est effectuée en soustrayant la moyenne de chaque caractéristique et en divisant par l'écart-type, ce qui permet de centrer les données autour de zéro et de les mettre à la même échelle.\n",
    "\n",
    "### PCA \n",
    "C'est une classe de scikit-learn qui représente l'analyse en composantes principales (ACP). L'ACP est une technique de réduction de dimensionnalité qui permet de projeter les données dans un nouvel espace de caractéristiques tout en conservant le maximum d'information possible. Elle est couramment utilisée pour réduire la complexité des données.\n",
    "\n",
    "### RandomForestClassifier \n",
    "C'est une classe de scikit-learn qui représente un modèle d'apprentissage automatique basé sur une forêt aléatoire pour la classification. Une forêt aléatoire est un ensemble d'arbres de décision, où chaque arbre est entraîné sur un sous-ensemble aléatoire des données. C'est un algorithme puissant pour la classification et la régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vFMZtW69DHJ"
   },
   "source": [
    "Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Ko2ZdMfxOe"
   },
   "outputs": [],
   "source": [
    "#create the pipeline\n",
    "ML_pipeline = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=4),\n",
    "                        RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StandardScaler() est la première étape du pipeline. Elle normalise (met à l'échelle) les données d'entrée en soustrayant la moyenne et en divisant par l'écart-type. Cela est important pour de nombreux algorithmes d'apprentissage automatique, car il est préférable que toutes les caractéristiques aient la même échelle.\n",
    "\n",
    "- PCA(n_components=4) C'est la deuxième étape du pipeline. Elle effectue l'analyse en composantes principales (ACP) pour réduire la dimension des données à 4 composantes principales. L'ACP est utilisée pour la réduction de dimensionnalité et la création de nouvelles caractéristiques qui capturent le maximum d'information à partir des caractéristiques originales.\n",
    "\n",
    "- RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, random_state=1) est la troisième étape du pipeline. Elle utilise un modèle de forêt aléatoire pour la classification. Les hyperparamètres spécifiés incluent le critère de division des arbres (entropy), le nombre d'estimateurs (arbres) dans la forêt (100), la profondeur maximale des arbres (5), et la graine aléatoire (random_state=1) pour garantir la reproductibilité des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INlo5E019LYo"
   },
   "source": [
    "Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BEc0LRk4G5I",
    "outputId": "7c3764ba-0a87-4e64-d4b0-36bf013c586d"
   },
   "outputs": [],
   "source": [
    "\n",
    "x=wine.loc[:, 'fixed acidity':'alcohol']# we can  also do this : x = wine.drop('quality', axis=1)\n",
    "y=wine.loc[:, 'quality']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11u7YxAL4O3D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_size=0.20 spécifie que 20 % des données seront réservées pour l'ensemble de test, tandis que les 80 % restants seront utilisés pour l'ensemble d'entraînement.\n",
    "\n",
    "- stratify=y signifie que la division des données sera effectuée de manière stratifiée en fonction des valeurs de y. Cela garantit que la répartition des classes dans l'ensemble de test sera similaire à celle dans l'ensemble d'entraînement. C'est important pour les tâches de classification, en particulier lorsque les classes sont déséquilibrées.\n",
    "\n",
    "- random_state=1 fixe une graine aléatoire pour assurer la reproductibilité de la division des données. Cela signifie que si vous exécutez le code à plusieurs reprises avec la même graine, vous obtiendrez toujours la même répartition des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmBe5SFs9U9n"
   },
   "source": [
    "pipeline fitting\n",
    "\n",
    "- ML_pipeline.fit(x_train, y_train) entraîne le modèle défini dans le pipeline ML_pipeline en utilisant les données d'entraînement x_train et les étiquettes cibles correspondantes y_train. Cela signifie que le modèle apprend à partir de ces données pour effectuer des prédictions ultérieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJh7Kc_oxdUY",
    "outputId": "dee7360c-b66f-407d-b67e-f0a9b235f450"
   },
   "outputs": [],
   "source": [
    "ML_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ML_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML_pipeline.predict(x_test) est utilisé pour effectuer des prédictions sur l'ensemble de test x_test. Les prédictions sont stockées dans la variable y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = ML_pipeline.score(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML_pipeline.score(x_test, y_test) calcule la précision du modèle sur l'ensemble de test. \n",
    " La précision est la proportion de prédictions correctes parmi toutes les prédictions effectuées sur  l'ensemble de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=(y_test==y_pred)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cette ligne compare les prédictions y_pred avec les véritables étiquettes de test y_test. Elle crée un tableau booléen diff qui indique quelles prédictions sont correctes (True) et quelles prédictions sont incorrectes (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ViJJYRUwBlM",
    "outputId": "b2f8f027-cb02-4c1e-be99-f2b1a0a2fcd8"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(ML_pipeline, 'rf_classifier.pkl')\n",
    "# To load: RFmodel = joblib.load('rf_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEnh13cpwJT4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R85DWFR26hD",
    "outputId": "6f09d3c5-3a27-441d-9c87-fdb00ce65470"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "group_names = ['bad', 'good']\n",
    "catego = pd.cut(y, bins = 2, labels = group_names)\n",
    "catego\n",
    "label_quality = preprocessing.LabelEncoder()\n",
    "# Bad becomes 0 and good becomes 1\n",
    "wine['quality'] = label_quality.fit_transform(catego)\n",
    "print(wine['quality'].value_counts())\n",
    "print(wine['quality'].head(20))\n",
    "y.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue la conversion d'une variable cible (étiquette) de type catégoriel en une variable binaire en utilisant le processus de binarisation. Voici des commentaires détaillés expliquant chaque ligne :\n",
    "\n",
    "- group_names = ['bad', 'good'] : Cette ligne définit les noms de groupe pour la binarisation. Les deux catégories possibles de la variable cible sont étiquetées comme \"bad\" (mauvaise) et \"good\" (bonne).\n",
    "\n",
    "- catego = pd.cut(y, bins=2, labels=group_names) : Cette ligne utilise la fonction pd.cut de pandas pour discrétiser (binariser) la variable cible y en deux catégories en utilisant deux intervalles (bins=2) et en attribuant les étiquettes définies précédemment (labels=group_names). Le résultat est stocké dans la variable catego. Lorsque vous utilisez la fonction pd.cut de pandas avec bins=2, elle divise les données en deux intervalles (ou bacs) en se basant sur les valeurs minimales et maximales des données. Les deux intervalles sont définis de manière à couvrir la plage complète des valeurs dans les données. Voici comment les intervalles sont définis : Le premier intervalle commence à la valeur minimale des données et s'étend jusqu'à un point médian entre la valeur minimale et la valeur maximale. Le deuxième intervalle commence juste après le point médian et s'étend jusqu'à la valeur maximale des données. En d'autres termes, la fonction pd.cut divise les données en deux intervalles égaux en termes de plage de valeurs. Tout ce qui est inférieur ou égal au point médian est placé dans le premier intervalle, tandis que tout ce qui est supérieur au point médian est placé dans le deuxième intervalle. Cela crée une binarisation des données, où chaque point de données appartient soit à la première catégorie (premier intervalle) soit à la deuxième catégorie (deuxième intervalle).\n",
    "\n",
    " - label_quality = preprocessing.LabelEncoder() : Cette ligne crée un encodeur d'étiquettes (LabelEncoder) de scikit-learn. Cet encodeur sera utilisé pour mapper les étiquettes \"bad\" et \"good\" en valeurs numériques.\n",
    " \n",
    " - wine['quality'] = label_quality.fit_transform(catego) : Cette ligne applique l'encodeur d'étiquettes aux valeurs de la variable catego et stocke les valeurs résultantes dans une nouvelle colonne appelée 'quality' dans le DataFrame wine. Les étiquettes \"bad\" sont converties en 0 et les étiquettes \"good\" sont converties en 1.\n",
    " \n",
    " - print(wine['quality'].value_counts()) : Cette ligne affiche le décompte des valeurs dans la colonne 'quality' du DataFrame wine, montrant combien de 0 et de 1 sont présents. Cela donne une idée de la répartition des deux catégories après la binarisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMRHAVeRA0kI",
    "outputId": "00eda3b8-0d28-4fae-c287-f7d07188bb58"
   },
   "outputs": [],
   "source": [
    "x=wine.loc[:, 'fixed acidity':'alcohol']# we can  also do this : x = wine.drop('quality', axis=1)\n",
    "y=wine.loc[:, 'quality']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=1)\n",
    "ML_pipeline.fit(x_train, y_train)\n",
    "y_pred = ML_pipeline.predict(x_test)\n",
    "test_acc = ML_pipeline.score(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "diff=(y_test==y_pred)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
