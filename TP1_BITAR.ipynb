{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctJOkCb59Ami"
   },
   "source": [
    "# TP1 Machine Learning - Ann\u00e9e 4 - ESILV - Septembre 2023\n",
    "Ibrahim BITAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_-eu0DKmEt1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numpy et pandas sont deux biblioth\u00e8ques Python populaires pour la manipulation de donn\u00e9es. numpy est principalement utilis\u00e9 pour effectuer des op\u00e9rations num\u00e9riques sur des tableaux, tandis que pandas est utilis\u00e9 pour travailler avec des donn\u00e9es tabulaires (comme les donn\u00e9es CSV) en utilisant des structures de donn\u00e9es appel\u00e9es DataFrames.\n",
    "\n",
    "\n",
    "- ColumnTransformer est une classe fournie par la biblioth\u00e8que scikit-learn (sklearn). Elle permet de g\u00e9rer diff\u00e9rentes transformations sur les colonnes d'un jeu de donn\u00e9es, ce qui est utile lorsque vous avez des colonnes avec diff\u00e9rents types de donn\u00e9es (num\u00e9riques, cat\u00e9goriques, textuelles) et que vous souhaitez les pr\u00e9traiter de mani\u00e8re sp\u00e9cifique.\n",
    "\n",
    "- Pipeline est une classe de scikit-learn qui permet de cr\u00e9er un flux de travail de traitement des donn\u00e9es et d'apprentissage automatique en cha\u00eenant plusieurs \u00e9tapes. Vous pouvez sp\u00e9cifier une s\u00e9quence d'op\u00e9rations \u00e0 effectuer, du pr\u00e9traitement des donn\u00e9es \u00e0 l'apprentissage du mod\u00e8le, le tout dans une seule structure.\n",
    "\n",
    "- SimpleImputer est utilis\u00e9 pour g\u00e9rer les valeurs manquantes dans les donn\u00e9es en leur attribuant une valeur sp\u00e9cifique (par exemple, la moyenne des valeurs non manquantes).\n",
    "\n",
    "- StandardScaler est utilis\u00e9 pour mettre \u00e0 l'\u00e9chelle les caract\u00e9ristiques num\u00e9riques afin qu'elles aient une moyenne de z\u00e9ro et un \u00e9cart-type de un. Cela est souvent n\u00e9cessaire pour de nombreux algorithmes d'apprentissage automatique.\n",
    "\n",
    "- OneHotEncoder est utilis\u00e9 pour transformer des variables cat\u00e9gorielles en variables binaires (0 ou 1) pour qu'elles puissent \u00eatre utilis\u00e9es dans les mod\u00e8les d'apprentissage automatique.\n",
    "\n",
    "- LogisticRegression est un mod\u00e8le d'apprentissage automatique couramment utilis\u00e9 pour la classification binaire.\n",
    "train_test_split est une fonction de scikit-learn qui est utilis\u00e9e pour diviser un ensemble de donn\u00e9es en ensembles d'entra\u00eenement et de test, ce qui est essentiel pour \u00e9valuer la performance d'un mod\u00e8le."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guIMQnm4puGX"
   },
   "source": [
    "As you can remark, a sample-data repository is created after running the previous code. You have access to california_housing_test.csv, california_housing_train.csv, mnist_test.csv and mnist_train_small.csv. You can import a local csv files to your sample_data repo. Let import now the winequality-red.csv that you can download to your local computer from this link  here: https://archive.ics.uci.edu/dataset/186/wine+quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyE2pVd-qdGr",
    "outputId": "e4778460-f60f-4e3a-c581-837c46c46e3d"
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"data/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_csv est une fonction de la biblioth\u00e8que pandas (pd) qui est utilis\u00e9e pour lire un fichier CSV et le stocker dans un DataFrame, une structure de donn\u00e9es tabulaire en deux dimensions.\n",
    "\n",
    "- \"data/winequality-red.csv\" est un chemin relatif vers le fichier CSV. Assurez-vous que le fichier se trouve dans un dossier `data` \u00e0 la racine du projet.\n",
    "\n",
    "- Pour r\u00e9cup\u00e9rer ce fichier si besoin, vous pouvez le t\u00e9l\u00e9charger depuis le [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv). Par exemple : `wget -O data/winequality-red.csv https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv`.\n",
    "\n",
    "- sep=';' sp\u00e9cifie le s\u00e9parateur de colonnes dans le fichier CSV. Dans ce cas, le point-virgule (;) est utilis\u00e9 comme s\u00e9parateur. Par d\u00e9faut, la virgule (,) est utilis\u00e9e comme s\u00e9parateur, mais cela peut varier selon les fichiers CSV."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wine.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wine.head(3) est utilis\u00e9 pour afficher les trois premi\u00e8res lignes du DataFrame wine. La m\u00e9thode head() est couramment utilis\u00e9e pour afficher un aper\u00e7u des premi\u00e8res lignes d'un DataFrame et est utile pour v\u00e9rifier rapidement les donn\u00e9es et s'assurer qu'elles ont \u00e9t\u00e9 charg\u00e9es correctement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf9Q9svo9Jsg"
   },
   "source": [
    "### Histogrammes des caract\u00e9ristiques\n",
    "Ces diagrammes permettent de visualiser la distribution de chaque variable pour rep\u00e9rer tendances g\u00e9n\u00e9rales et valeurs aberrantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "0lB8ZYeO8WFj",
    "outputId": "b4bfe2d0-e7a1-41a0-bf32-b31e86fde65c"
   },
   "outputs": [],
   "source": [
    "wine.hist(bins=20, figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wine.hist() g\u00e9n\u00e8re un histogramme pour chaque variable num\u00e9rique du DataFrame.\n",
    "- bins=20 sp\u00e9cifie le nombre de barres de chaque histogramme.\n",
    "- figsize=(15, 10) d\u00e9finit la taille de l'ensemble des graphiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "z2G6YycqC9zp",
    "outputId": "e6c96cdc-d49b-44af-d058-38d53cb56e27"
   },
   "outputs": [],
   "source": [
    "wine.plot(kind='box', subplots=True, layout=(3,4), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "dt-SSqF5I5EA",
    "outputId": "659ab3d4-7b8a-48ce-8d2d-6058598d2334"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(wine.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matrice de corr\u00e9lation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette heatmap met en \u00e9vidence les corr\u00e9lations entre les variables : les couleurs vives indiquent des relations fortes, positives ou n\u00e9gatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "QzzzSrq9MFeO",
    "outputId": "09c442da-b7bc-4b17-a73e-e2989cae2a6f"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(wine,figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaque case de la matrice contient un diagramme de dispersion qui montre la relation entre deux variables num\u00e9riques. La diagonale de la matrice contient des histogrammes de chaque variable par elle-m\u00eame.\n",
    "\n",
    "- Cette matrice permet de visualiser les relations entre toutes les paires de variables num\u00e9riques dans le jeu de donn\u00e9es sur la qualit\u00e9 du vin. Elle est utile pour d\u00e9tecter des tendances, des regroupements ou des valeurs aberrantes dans les donn\u00e9es. Chaque diagramme de dispersion montre comment deux variables num\u00e9riques sont distribu\u00e9es et s'il existe une relation lin\u00e9aire entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB-oBkfPfnXy"
   },
   "source": [
    "SKlearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-byNzLh3fuIB"
   },
   "outputs": [],
   "source": [
    "#import classes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarques \n",
    "### StandardScaler \n",
    "C'est une classe de scikit-learn qui est utilis\u00e9e pour mettre \u00e0 l'\u00e9chelle les caract\u00e9ristiques num\u00e9riques d'un ensemble de donn\u00e9es. La mise \u00e0 l'\u00e9chelle est effectu\u00e9e en soustrayant la moyenne de chaque caract\u00e9ristique et en divisant par l'\u00e9cart-type, ce qui permet de centrer les donn\u00e9es autour de z\u00e9ro et de les mettre \u00e0 la m\u00eame \u00e9chelle.\n",
    "\n",
    "### PCA \n",
    "C'est une classe de scikit-learn qui repr\u00e9sente l'analyse en composantes principales (ACP). L'ACP est une technique de r\u00e9duction de dimensionnalit\u00e9 qui permet de projeter les donn\u00e9es dans un nouvel espace de caract\u00e9ristiques tout en conservant le maximum d'information possible. Elle est couramment utilis\u00e9e pour r\u00e9duire la complexit\u00e9 des donn\u00e9es.\n",
    "\n",
    "### RandomForestClassifier \n",
    "C'est une classe de scikit-learn qui repr\u00e9sente un mod\u00e8le d'apprentissage automatique bas\u00e9 sur une for\u00eat al\u00e9atoire pour la classification. Une for\u00eat al\u00e9atoire est un ensemble d'arbres de d\u00e9cision, o\u00f9 chaque arbre est entra\u00een\u00e9 sur un sous-ensemble al\u00e9atoire des donn\u00e9es. C'est un algorithme puissant pour la classification et la r\u00e9gression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vFMZtW69DHJ"
   },
   "source": [
    "Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Ko2ZdMfxOe"
   },
   "outputs": [],
   "source": [
    "#create the pipeline\n",
    "ML_pipeline = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=4),\n",
    "                        RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StandardScaler() est la premi\u00e8re \u00e9tape du pipeline. Elle normalise (met \u00e0 l'\u00e9chelle) les donn\u00e9es d'entr\u00e9e en soustrayant la moyenne et en divisant par l'\u00e9cart-type. Cela est important pour de nombreux algorithmes d'apprentissage automatique, car il est pr\u00e9f\u00e9rable que toutes les caract\u00e9ristiques aient la m\u00eame \u00e9chelle.\n",
    "\n",
    "- PCA(n_components=4) C'est la deuxi\u00e8me \u00e9tape du pipeline. Elle effectue l'analyse en composantes principales (ACP) pour r\u00e9duire la dimension des donn\u00e9es \u00e0 4 composantes principales. L'ACP est utilis\u00e9e pour la r\u00e9duction de dimensionnalit\u00e9 et la cr\u00e9ation de nouvelles caract\u00e9ristiques qui capturent le maximum d'information \u00e0 partir des caract\u00e9ristiques originales.\n",
    "\n",
    "- RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, random_state=1) est la troisi\u00e8me \u00e9tape du pipeline. Elle utilise un mod\u00e8le de for\u00eat al\u00e9atoire pour la classification. Les hyperparam\u00e8tres sp\u00e9cifi\u00e9s incluent le crit\u00e8re de division des arbres (entropy), le nombre d'estimateurs (arbres) dans la for\u00eat (100), la profondeur maximale des arbres (5), et la graine al\u00e9atoire (random_state=1) pour garantir la reproductibilit\u00e9 des r\u00e9sultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INlo5E019LYo"
   },
   "source": [
    "Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BEc0LRk4G5I",
    "outputId": "7c3764ba-0a87-4e64-d4b0-36bf013c586d"
   },
   "outputs": [],
   "source": [
    "\n",
    "x=wine.loc[:, 'fixed acidity':'alcohol']# we can  also do this : x = wine.drop('quality', axis=1)\n",
    "y=wine.loc[:, 'quality']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11u7YxAL4O3D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_size=0.20 sp\u00e9cifie que 20 % des donn\u00e9es seront r\u00e9serv\u00e9es pour l'ensemble de test, tandis que les 80 % restants seront utilis\u00e9s pour l'ensemble d'entra\u00eenement.\n",
    "\n",
    "- stratify=y signifie que la division des donn\u00e9es sera effectu\u00e9e de mani\u00e8re stratifi\u00e9e en fonction des valeurs de y. Cela garantit que la r\u00e9partition des classes dans l'ensemble de test sera similaire \u00e0 celle dans l'ensemble d'entra\u00eenement. C'est important pour les t\u00e2ches de classification, en particulier lorsque les classes sont d\u00e9s\u00e9quilibr\u00e9es.\n",
    "\n",
    "- random_state=1 fixe une graine al\u00e9atoire pour assurer la reproductibilit\u00e9 de la division des donn\u00e9es. Cela signifie que si vous ex\u00e9cutez le code \u00e0 plusieurs reprises avec la m\u00eame graine, vous obtiendrez toujours la m\u00eame r\u00e9partition des donn\u00e9es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmBe5SFs9U9n"
   },
   "source": [
    "pipeline fitting\n",
    "\n",
    "- ML_pipeline.fit(x_train, y_train) entra\u00eene le mod\u00e8le d\u00e9fini dans le pipeline ML_pipeline en utilisant les donn\u00e9es d'entra\u00eenement x_train et les \u00e9tiquettes cibles correspondantes y_train. Cela signifie que le mod\u00e8le apprend \u00e0 partir de ces donn\u00e9es pour effectuer des pr\u00e9dictions ult\u00e9rieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJh7Kc_oxdUY",
    "outputId": "dee7360c-b66f-407d-b67e-f0a9b235f450"
   },
   "outputs": [],
   "source": [
    "ML_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ML_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML_pipeline.predict(x_test) est utilis\u00e9 pour effectuer des pr\u00e9dictions sur l'ensemble de test x_test. Les pr\u00e9dictions sont stock\u00e9es dans la variable y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = ML_pipeline.score(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML_pipeline.score(x_test, y_test) calcule la pr\u00e9cision du mod\u00e8le sur l'ensemble de test. \n",
    " La pr\u00e9cision est la proportion de pr\u00e9dictions correctes parmi toutes les pr\u00e9dictions effectu\u00e9es sur  l'ensemble de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=(y_test==y_pred)\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cette ligne compare les pr\u00e9dictions y_pred avec les v\u00e9ritables \u00e9tiquettes de test y_test. Elle cr\u00e9e un tableau bool\u00e9en diff qui indique quelles pr\u00e9dictions sont correctes (True) et quelles pr\u00e9dictions sont incorrectes (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ViJJYRUwBlM",
    "outputId": "b2f8f027-cb02-4c1e-be99-f2b1a0a2fcd8"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(ML_pipeline, 'rf_classifier.pkl')\n",
    "# To load: RFmodel = joblib.load('rf_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEnh13cpwJT4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R85DWFR26hD",
    "outputId": "6f09d3c5-3a27-441d-9c87-fdb00ce65470"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "group_names = ['bad', 'good']\n",
    "catego = pd.cut(y, bins = 2, labels = group_names)\n",
    "catego\n",
    "label_quality = preprocessing.LabelEncoder()\n",
    "# Bad becomes 0 and good becomes 1\n",
    "wine['quality'] = label_quality.fit_transform(catego)\n",
    "print(wine['quality'].value_counts())\n",
    "print(wine['quality'].head(20))\n",
    "y.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue la conversion d'une variable cible (\u00e9tiquette) de type cat\u00e9goriel en une variable binaire en utilisant le processus de binarisation. Voici des commentaires d\u00e9taill\u00e9s expliquant chaque ligne :\n",
    "\n",
    "- group_names = ['bad', 'good'] : Cette ligne d\u00e9finit les noms de groupe pour la binarisation. Les deux cat\u00e9gories possibles de la variable cible sont \u00e9tiquet\u00e9es comme \"bad\" (mauvaise) et \"good\" (bonne).\n",
    "\n",
    "- catego = pd.cut(y, bins=2, labels=group_names) : Cette ligne utilise la fonction pd.cut de pandas pour discr\u00e9tiser (binariser) la variable cible y en deux cat\u00e9gories en utilisant deux intervalles (bins=2) et en attribuant les \u00e9tiquettes d\u00e9finies pr\u00e9c\u00e9demment (labels=group_names). Le r\u00e9sultat est stock\u00e9 dans la variable catego. Lorsque vous utilisez la fonction pd.cut de pandas avec bins=2, elle divise les donn\u00e9es en deux intervalles (ou bacs) en se basant sur les valeurs minimales et maximales des donn\u00e9es. Les deux intervalles sont d\u00e9finis de mani\u00e8re \u00e0 couvrir la plage compl\u00e8te des valeurs dans les donn\u00e9es. Voici comment les intervalles sont d\u00e9finis : Le premier intervalle commence \u00e0 la valeur minimale des donn\u00e9es et s'\u00e9tend jusqu'\u00e0 un point m\u00e9dian entre la valeur minimale et la valeur maximale. Le deuxi\u00e8me intervalle commence juste apr\u00e8s le point m\u00e9dian et s'\u00e9tend jusqu'\u00e0 la valeur maximale des donn\u00e9es. En d'autres termes, la fonction pd.cut divise les donn\u00e9es en deux intervalles \u00e9gaux en termes de plage de valeurs. Tout ce qui est inf\u00e9rieur ou \u00e9gal au point m\u00e9dian est plac\u00e9 dans le premier intervalle, tandis que tout ce qui est sup\u00e9rieur au point m\u00e9dian est plac\u00e9 dans le deuxi\u00e8me intervalle. Cela cr\u00e9e une binarisation des donn\u00e9es, o\u00f9 chaque point de donn\u00e9es appartient soit \u00e0 la premi\u00e8re cat\u00e9gorie (premier intervalle) soit \u00e0 la deuxi\u00e8me cat\u00e9gorie (deuxi\u00e8me intervalle).\n",
    "\n",
    " - label_quality = preprocessing.LabelEncoder() : Cette ligne cr\u00e9e un encodeur d'\u00e9tiquettes (LabelEncoder) de scikit-learn. Cet encodeur sera utilis\u00e9 pour mapper les \u00e9tiquettes \"bad\" et \"good\" en valeurs num\u00e9riques.\n",
    " \n",
    " - wine['quality'] = label_quality.fit_transform(catego) : Cette ligne applique l'encodeur d'\u00e9tiquettes aux valeurs de la variable catego et stocke les valeurs r\u00e9sultantes dans une nouvelle colonne appel\u00e9e 'quality' dans le DataFrame wine. Les \u00e9tiquettes \"bad\" sont converties en 0 et les \u00e9tiquettes \"good\" sont converties en 1.\n",
    " \n",
    " - print(wine['quality'].value_counts()) : Cette ligne affiche le d\u00e9compte des valeurs dans la colonne 'quality' du DataFrame wine, montrant combien de 0 et de 1 sont pr\u00e9sents. Cela donne une id\u00e9e de la r\u00e9partition des deux cat\u00e9gories apr\u00e8s la binarisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMRHAVeRA0kI",
    "outputId": "00eda3b8-0d28-4fae-c287-f7d07188bb58"
   },
   "outputs": [],
   "source": [
    "x=wine.loc[:, 'fixed acidity':'alcohol']# we can  also do this : x = wine.drop('quality', axis=1)\n",
    "y=wine.loc[:, 'quality']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=1)\n",
    "ML_pipeline.fit(x_train, y_train)\n",
    "y_pred = ML_pipeline.predict(x_test)\n",
    "test_acc = ML_pipeline.score(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "diff=(y_test==y_pred)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}